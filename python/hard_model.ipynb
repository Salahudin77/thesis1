{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salahudin77/thesis/blob/main/python/hard_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import time\n",
        "import gc\n",
        "import os\n",
        "import psutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import json\n",
        "from datetime import datetime\n",
        "import threading\n",
        "from collections import defaultdict\n",
        "import platform\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MemoryTracker:\n",
        "    def __init__(self, interval_ms=10):\n",
        "        self.interval_ms = interval_ms / 1000.0  # Convert to seconds\n",
        "        self.process = psutil.Process(os.getpid())\n",
        "        self.peak_memory = 0\n",
        "        self.memory_samples = []\n",
        "        self.is_running = False\n",
        "        self.thread = None\n",
        "        self.start_time = None\n",
        "        self.end_time = None\n",
        "        \n",
        "    def _track_memory(self):\n",
        "        while self.is_running:\n",
        "            mem = self.process.memory_info().rss\n",
        "            self.memory_samples.append({\n",
        "                'timestamp': time.time(),\n",
        "                'memory_bytes': mem,\n",
        "                'memory_mb': mem / (1024 * 1024)\n",
        "            })\n",
        "            self.peak_memory = max(self.peak_memory, mem)\n",
        "            time.sleep(self.interval_ms)\n",
        "    \n",
        "    def start(self):\n",
        "        if not self.is_running:\n",
        "            self.is_running = True\n",
        "            self.start_time = time.time()\n",
        "            self.thread = threading.Thread(target=self._track_memory)\n",
        "            self.thread.daemon = True\n",
        "            self.thread.start()\n",
        "    \n",
        "    def stop(self):\n",
        "        if self.is_running:\n",
        "            self.is_running = False\n",
        "            self.end_time = time.time()\n",
        "            if self.thread is not None:\n",
        "                self.thread.join()\n",
        "    \n",
        "    def get_peak_memory_mb(self):\n",
        "        return self.peak_memory / (1024 * 1024)\n",
        "    \n",
        "    def get_summary(self):\n",
        "        duration = (self.end_time - self.start_time) * 1000 if self.end_time else 0\n",
        "        return {\n",
        "            'duration_ms': duration,\n",
        "            'sample_count': len(self.memory_samples),\n",
        "            'sample_interval_ms': self.interval_ms * 1000,\n",
        "            'peak_memory_mb': self.get_peak_memory_mb(),\n",
        "            'start_time': self.start_time,\n",
        "            'end_time': self.end_time\n",
        "        }\n",
        "    \n",
        "    def get_time_series_data(self):\n",
        "        if not self.memory_samples:\n",
        "            return []\n",
        "        \n",
        "        base_time = self.memory_samples[0]['timestamp']\n",
        "        return [{\n",
        "            'time_ms': (sample['timestamp'] - base_time) * 1000,\n",
        "            'memory_mb': sample['memory_mb']\n",
        "        } for sample in self.memory_samples]\n",
        "\n",
        "class TrainingResult:\n",
        "    def __init__(self, time_ms, memory_used_mb, cpu_time_ms, peak_memory_mb, final_accuracy, memory_profile):\n",
        "        self.time_ms = time_ms\n",
        "        self.memory_used_mb = memory_used_mb\n",
        "        self.cpu_time_ms = cpu_time_ms\n",
        "        self.peak_memory_mb = peak_memory_mb\n",
        "        self.final_accuracy = final_accuracy\n",
        "        self.memory_profile = memory_profile\n",
        "\n",
        "class InferenceResult:\n",
        "    def __init__(self, prediction, time_ms, memory_used_mb, cpu_time_ms, peak_memory_mb, memory_profile):\n",
        "        self.prediction = prediction\n",
        "        self.time_ms = time_ms\n",
        "        self.memory_used_mb = memory_used_mb\n",
        "        self.cpu_time_ms = cpu_time_ms\n",
        "        self.peak_memory_mb = peak_memory_mb\n",
        "        self.memory_profile = memory_profile\n",
        "\n",
        "def create_hard_network():\n",
        "    # Complex CNN with multiple convolutional layers - matching Java version exactly\n",
        "    model = models.Sequential([\n",
        "        # First conv layer: 20 filters of size 5x5, matching Java's ConvolutionLayer\n",
        "        layers.Conv2D(20, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)),\n",
        "        \n",
        "        # First pooling layer: 2x2 max pooling with stride 2x2\n",
        "        layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "        \n",
        "        # Second conv layer: 50 filters of size 5x5\n",
        "        layers.Conv2D(50, (5, 5), strides=(1, 1), activation='relu'),\n",
        "        \n",
        "        # Second pooling layer: 2x2 max pooling with stride 2x2\n",
        "        layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "        \n",
        "        # Flatten layer\n",
        "        layers.Flatten(),\n",
        "        \n",
        "        # Dense layer with 256 neurons\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        \n",
        "        # Output layer with 10 neurons (for 10 digits)\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "def measure_training_performance(model):\n",
        "    gc.collect()\n",
        "    time.sleep(0.1)\n",
        "    \n",
        "    # Get initial memory usage\n",
        "    process = psutil.Process(os.getpid())\n",
        "    start_mem = process.memory_info().rss\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Training configuration matching Java version\n",
        "    batch_size = 64\n",
        "    num_epochs = 10\n",
        "    \n",
        "    # Load training data\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "    \n",
        "    # Start memory tracking\n",
        "    memory_tracker = MemoryTracker(500)  # 500ms interval like Java version\n",
        "    memory_tracker.start()\n",
        "    \n",
        "    # Training loop\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        model.fit(\n",
        "            x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=1,\n",
        "            verbose=0\n",
        "        )\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "    \n",
        "    # Evaluate the model\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "    \n",
        "    # Stop memory tracking\n",
        "    memory_tracker.stop()\n",
        "    end_time = time.time()\n",
        "    end_mem = process.memory_info().rss\n",
        "    \n",
        "    # Calculate metrics\n",
        "    time_ms = (end_time - start_time) * 1000\n",
        "    memory_used_mb = (end_mem - start_mem) / (1024 * 1024)\n",
        "    peak_memory_mb = memory_tracker.get_peak_memory_mb()\n",
        "    \n",
        "    # Create memory profile\n",
        "    memory_profile = {\n",
        "        'summary': memory_tracker.get_summary(),\n",
        "        'time_series': memory_tracker.get_time_series_data()\n",
        "    }\n",
        "    \n",
        "    print(\"\\n===== Training Performance =====\")\n",
        "    print(f\"Training time: {time_ms:.2f} ms ({time_ms/1000:.2f} seconds)\")\n",
        "    print(f\"Memory used (end-start): {memory_used_mb:.2f} MB\")\n",
        "    print(f\"Peak memory used: {peak_memory_mb:.2f} MB\")\n",
        "    print(f\"Final model accuracy: {test_acc*100:.2f}%\")\n",
        "    \n",
        "    return TrainingResult(time_ms, memory_used_mb, -1, peak_memory_mb, test_acc, memory_profile)\n",
        "\n",
        "def test_network(model, image_path, runs=5):\n",
        "    # Warm-up phase\n",
        "    print(\"Performing warm-up iterations...\")\n",
        "    for _ in range(10):\n",
        "        warmup_iteration(model, image_path)\n",
        "    print(\"Warm-up complete, starting benchmark...\")\n",
        "    \n",
        "    gc.collect()\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    inference_results = []\n",
        "    \n",
        "    for i in range(runs):\n",
        "        print(f\"\\n--- Test Run {i+1} ---\")\n",
        "        result = run_inference(model, image_path)\n",
        "        inference_results.append(result)\n",
        "    \n",
        "    # Aggregate results\n",
        "    avg_time = np.mean([r.time_ms for r in inference_results])\n",
        "    std_dev_time = np.std([r.time_ms for r in inference_results])\n",
        "    avg_memory = np.mean([r.memory_used_mb for r in inference_results])\n",
        "    std_dev_memory = np.std([r.memory_used_mb for r in inference_results])\n",
        "    avg_peak_memory = np.mean([r.peak_memory_mb for r in inference_results])\n",
        "    std_dev_peak_memory = np.std([r.peak_memory_mb for r in inference_results])\n",
        "    \n",
        "    # Find most common prediction\n",
        "    predictions = [r.prediction for r in inference_results]\n",
        "    common_prediction = max(set(predictions), key=predictions.count)\n",
        "    \n",
        "    print(\"\\n===== Average Inference Results After 5 Runs =====\")\n",
        "    print(f\"Most common prediction: {common_prediction}\")\n",
        "    print(f\"Average execution time: {avg_time:.2f} ms (±{std_dev_time:.2f})\")\n",
        "    print(f\"Average memory used: {avg_memory:.2f} MB (±{std_dev_memory:.2f})\")\n",
        "    print(f\"Average peak memory: {avg_peak_memory:.2f} MB (±{std_dev_peak_memory:.2f})\")\n",
        "    \n",
        "    return inference_results, avg_time, std_dev_time, avg_memory, std_dev_memory, avg_peak_memory, std_dev_peak_memory, common_prediction\n",
        "\n",
        "def run_inference(model, image_path):\n",
        "    gc.collect()\n",
        "    time.sleep(0.1)\n",
        "    \n",
        "    process = psutil.Process(os.getpid())\n",
        "    start_mem = process.memory_info().rss\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Start memory tracking with 10ms intervals\n",
        "    memory_tracker = MemoryTracker(10)\n",
        "    memory_tracker.start()\n",
        "    \n",
        "    try:\n",
        "        # Load and preprocess image\n",
        "        img = Image.open(image_path).convert('L')\n",
        "        img = img.resize((28, 28))\n",
        "        img_array = np.array(img) / 255.0\n",
        "        img_array = img_array.reshape(1, 28, 28, 1)\n",
        "        \n",
        "        # Run prediction\n",
        "        predictions = model.predict(img_array, verbose=0)\n",
        "        prediction = np.argmax(predictions[0])\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "        prediction = -1\n",
        "    \n",
        "    end_time = time.time()\n",
        "    memory_tracker.stop()\n",
        "    end_mem = process.memory_info().rss\n",
        "    \n",
        "    # Calculate metrics\n",
        "    time_ms = (end_time - start_time) * 1000\n",
        "    memory_used_mb = (end_mem - start_mem) / (1024 * 1024)\n",
        "    peak_memory_mb = memory_tracker.get_peak_memory_mb()\n",
        "    \n",
        "    # Create memory profile\n",
        "    memory_profile = {\n",
        "        'summary': memory_tracker.get_summary(),\n",
        "        'time_series': memory_tracker.get_time_series_data()\n",
        "    }\n",
        "    \n",
        "    print(f\"Prediction: {prediction}\")\n",
        "    print(f\"Execution time: {time_ms:.2f} ms\")\n",
        "    print(f\"Memory used (end-start): {memory_used_mb:.2f} MB\")\n",
        "    print(f\"Peak memory used: {peak_memory_mb:.2f} MB\")\n",
        "    \n",
        "    return InferenceResult(prediction, time_ms, memory_used_mb, -1, peak_memory_mb, memory_profile)\n",
        "\n",
        "def warmup_iteration(model, image_path):\n",
        "    try:\n",
        "        img = Image.open(image_path).convert('L')\n",
        "        img = img.resize((28, 28))\n",
        "        img_array = np.array(img) / 255.0\n",
        "        img_array = img_array.reshape(1, 28, 28, 1)\n",
        "        model.predict(img_array, verbose=0)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def save_to_json(inference_results, training_result, avg_time, std_dev_time, \n",
        "                avg_memory, std_dev_memory, avg_peak_memory, std_dev_peak_memory,\n",
        "                common_prediction, filename=\"hard_memory_results64.json\"):\n",
        "    \n",
        "    # Convert numpy types to native Python types\n",
        "    def convert(o):\n",
        "        if isinstance(o, np.generic):\n",
        "            return o.item()\n",
        "        if isinstance(o, dict):\n",
        "            return {k: convert(v) for k, v in o.items()}\n",
        "        if isinstance(o, (list, tuple)):\n",
        "            return [convert(i) for i in o]\n",
        "        return o\n",
        "    \n",
        "    root = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'system_info': get_system_info(),\n",
        "        'training': {\n",
        "            'execution_time_ms': convert(training_result.time_ms),\n",
        "            'execution_time_sec': convert(training_result.time_ms / 1000),\n",
        "            'cpu_time_ms': convert(training_result.cpu_time_ms),\n",
        "            'memory_used_mb': convert(training_result.memory_used_mb),\n",
        "            'peak_memory_mb': convert(training_result.peak_memory_mb),\n",
        "            'final_accuracy': convert(training_result.final_accuracy),\n",
        "            'memory_profile': convert(training_result.memory_profile['summary'])\n",
        "        },\n",
        "        'inference_runs': [{\n",
        "            'run': i+1,\n",
        "            'prediction': convert(r.prediction),\n",
        "            'execution_time_ms': convert(r.time_ms),\n",
        "            'cpu_time_ms': convert(r.cpu_time_ms),\n",
        "            'memory_used_mb': convert(r.memory_used_mb),\n",
        "            'peak_memory_mb': convert(r.peak_memory_mb),\n",
        "            'memory_profile': convert(r.memory_profile['summary'])\n",
        "        } for i, r in enumerate(inference_results)],\n",
        "        'inference_summary': {\n",
        "            'average_execution_time_ms': convert(avg_time),\n",
        "            'std_dev_execution_time_ms': convert(std_dev_time),\n",
        "            'average_memory_used_mb': convert(avg_memory),\n",
        "            'std_dev_memory_used_mb': convert(std_dev_memory),\n",
        "            'average_peak_memory_mb': convert(avg_peak_memory),\n",
        "            'std_dev_peak_memory_mb': convert(std_dev_peak_memory),\n",
        "            'most_common_prediction': convert(common_prediction)\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(root, f, indent=4)\n",
        "    print(f\"Results exported to {filename}\")\n",
        "\n",
        "def get_system_info():\n",
        "    return {\n",
        "        'available_processors': multiprocessing.cpu_count(),\n",
        "        'max_memory_mb': psutil.virtual_memory().total / (1024 * 1024),\n",
        "        'os_name': platform.system(),\n",
        "        'os_version': platform.release(),\n",
        "        'os_arch': platform.machine(),\n",
        "        'python_version': platform.python_version(),\n",
        "        'tensorflow_version': tf.__version__\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHQC7gtFrOvG",
        "outputId": "bdb8b3af-e563-4ac1-e570-dae8d5cc681e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 24, 24, 20)        520       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 12, 12, 20)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 8, 8, 50)          25050     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 4, 4, 50)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                51264     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77,484\n",
            "Trainable params: 77,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Starting training performance measurement...\n",
            "Starting training...\n",
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Training complete!\n",
            "Test accuracy: 0.9904\n",
            "\n",
            "===== Training Performance =====\n",
            "Training time: 536404.51 ms (536.40 seconds)\n",
            "Memory used (end-start): 1178.24 MB\n",
            "Peak memory used: 1978.17 MB\n",
            "Final model accuracy: 99.04%\n",
            "Performing warm-up iterations...\n",
            "Warm-up complete, starting benchmark...\n",
            "\n",
            "--- Test Run 1 ---\n",
            "Prediction: 2\n",
            "Execution time: 48.75 ms\n",
            "Memory used (end-start): 0.30 MB\n",
            "Peak memory used: 529.39 MB\n",
            "\n",
            "--- Test Run 2 ---\n",
            "Prediction: 2\n",
            "Execution time: 48.58 ms\n",
            "Memory used (end-start): 0.05 MB\n",
            "Peak memory used: 529.52 MB\n",
            "\n",
            "--- Test Run 3 ---\n",
            "Prediction: 2\n",
            "Execution time: 49.78 ms\n",
            "Memory used (end-start): 0.02 MB\n",
            "Peak memory used: 529.55 MB\n",
            "\n",
            "--- Test Run 4 ---\n",
            "Prediction: 2\n",
            "Execution time: 48.82 ms\n",
            "Memory used (end-start): 0.26 MB\n",
            "Peak memory used: 529.66 MB\n",
            "\n",
            "--- Test Run 5 ---\n",
            "Prediction: 2\n",
            "Execution time: 49.74 ms\n",
            "Memory used (end-start): 0.02 MB\n",
            "Peak memory used: 529.80 MB\n",
            "\n",
            "===== Average Inference Results After 5 Runs =====\n",
            "Most common prediction: 2\n",
            "Average execution time: 49.13 ms (±0.52)\n",
            "Average memory used: 0.13 MB (±0.12)\n",
            "Average peak memory: 529.59 MB (±0.14)\n",
            "Results exported to hard_memory_results64.json\n",
            "Model saved to trained-hard-model.h5\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # Create the model\n",
        "    model = create_hard_network()\n",
        "    model.summary()\n",
        "    \n",
        "    # Measure training performance\n",
        "    print(\"Starting training performance measurement...\")\n",
        "    training_result = measure_training_performance(model)\n",
        "    \n",
        "    # Test the network\n",
        "    image_path = \"träningsbilder/testSample/img_1.jpg\"\n",
        "    try:\n",
        "        inference_results, avg_time, std_dev_time, avg_memory, std_dev_memory, \\\n",
        "        avg_peak_memory, std_dev_peak_memory, common_prediction = test_network(model, image_path)\n",
        "        \n",
        "        # Save combined results to JSON\n",
        "        save_to_json(inference_results, training_result, avg_time, std_dev_time, \n",
        "                    avg_memory, std_dev_memory, avg_peak_memory, std_dev_peak_memory,\n",
        "                    common_prediction)\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        print(f\"Test image not found at {image_path}. Testing on a random test sample instead.\")\n",
        "        (_, _), (x_test, y_test) = mnist.load_data()\n",
        "        test_idx = np.random.randint(0, len(x_test))\n",
        "        test_img = x_test[test_idx] / 255.0\n",
        "        test_img = test_img.reshape(1, 28, 28, 1)\n",
        "        \n",
        "        # Run a single inference\n",
        "        predictions = model.predict(test_img, verbose=0)\n",
        "        prediction = np.argmax(predictions[0])\n",
        "        print(f\"Test sample true label: {y_test[test_idx]}, prediction: {prediction}\")\n",
        "    \n",
        "    # Save the trained model\n",
        "    model.save(\"trained-hard-model.h5\")\n",
        "    print(\"Model saved to trained-hard-model.h5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOFbZvVEFYQfE7uLGcEaAYt",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "exJobbEnv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
