{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salahudin77/thesis/blob/main/python/easy_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import time\n",
        "import gc\n",
        "import os\n",
        "import psutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import json\n",
        "import datetime\n",
        "import platform\n",
        "import statistics\n",
        "import threading\n",
        "import sys\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MemoryTracker:\n",
        "    def __init__(self, interval_ms=100):\n",
        "        self.interval_ms = interval_ms\n",
        "        self.memory_stats = []\n",
        "        self.running = False\n",
        "        self.thread = None\n",
        "        self.start_time = None\n",
        "        self.end_time = None\n",
        "        self.peak_memory_usage = 0\n",
        "        \n",
        "    def collect_stats(self):\n",
        "        process = psutil.Process(os.getpid())\n",
        "        stats = {\n",
        "            'timestamp': time.time() * 1000,  # convert to ms\n",
        "            'memory_used_bytes': process.memory_info().rss,\n",
        "            'memory_used_mb': process.memory_info().rss / 1024 / 1024\n",
        "        }\n",
        "        self.peak_memory_usage = max(self.peak_memory_usage, stats['memory_used_bytes'])\n",
        "        self.memory_stats.append(stats)\n",
        "        \n",
        "    def track_loop(self):\n",
        "        while self.running:\n",
        "            self.collect_stats()\n",
        "            time.sleep(self.interval_ms / 1000)  # convert ms to seconds\n",
        "            \n",
        "    def start(self):\n",
        "        if not self.running:\n",
        "            self.running = True\n",
        "            self.start_time = time.time()\n",
        "            self.thread = threading.Thread(target=self.track_loop)\n",
        "            self.thread.daemon = True\n",
        "            self.thread.start()\n",
        "            \n",
        "    def stop(self):\n",
        "        if self.running:\n",
        "            self.running = False\n",
        "            self.end_time = time.time()\n",
        "            if self.thread:\n",
        "                self.thread.join(timeout=0.5)\n",
        "                \n",
        "    def get_peak_memory_mb(self):\n",
        "        return self.peak_memory_usage / 1024 / 1024\n",
        "        \n",
        "    def get_summary(self):\n",
        "        summary = {\n",
        "            'duration_ms': int((self.end_time - self.start_time) * 1000) if self.start_time and self.end_time else 0,\n",
        "            'sample_count': len(self.memory_stats),\n",
        "            'sample_interval_ms': self.interval_ms,\n",
        "            'peak_total_mb': self.get_peak_memory_mb(),\n",
        "        }\n",
        "        return summary\n",
        "        \n",
        "    def get_timeseries_data(self):\n",
        "        if not self.memory_stats:\n",
        "            return []\n",
        "            \n",
        "        base_time = self.memory_stats[0]['timestamp']\n",
        "        timeseries = []\n",
        "        \n",
        "        for stats in self.memory_stats:\n",
        "            point = {\n",
        "                'time_ms': int(stats['timestamp'] - base_time),\n",
        "                'heap_mb': stats['memory_used_mb'],  # Python doesn't separate heap/non-heap like Java\n",
        "                'non_heap_mb': 0  # Not applicable in Python\n",
        "            }\n",
        "            timeseries.append(point)\n",
        "            \n",
        "        return timeseries\n",
        "        \n",
        "    def __enter__(self):\n",
        "        self.start()\n",
        "        return self\n",
        "        \n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        self.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class InferenceResult:\n",
        "    def __init__(self, prediction, time_ms, memory_used_mb, cpu_time_ms, peak_memory_mb, memory_profile):\n",
        "        self.prediction = prediction\n",
        "        self.time_ms = time_ms\n",
        "        self.memory_used_mb = memory_used_mb\n",
        "        self.cpu_time_ms = cpu_time_ms\n",
        "        self.peak_memory_mb = peak_memory_mb\n",
        "        self.memory_profile = memory_profile\n",
        "\n",
        "class TrainingResult:\n",
        "    def __init__(self, time_ms, memory_used_mb, cpu_time_ms, peak_memory_mb, accuracy, memory_profile):\n",
        "        self.time_ms = time_ms\n",
        "        self.memory_used_mb = memory_used_mb\n",
        "        self.cpu_time_ms = cpu_time_ms\n",
        "        self.peak_memory_mb = peak_memory_mb\n",
        "        self.accuracy = accuracy\n",
        "        self.memory_profile = memory_profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_easy_network():\n",
        "    \"\"\"Create a simple neural network matching the Java version\"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28)),  # This matches the Java 28*28 input\n",
        "        layers.Dense(64, activation='relu'),    # Same as Java (nOut=64)\n",
        "        layers.Dense(10, activation='softmax')  # Output layer same as Java (nOut=10)\n",
        "    ])\n",
        "    \n",
        "    # Use Adam with 0.001 learning rate to match Java\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "def get_used_memory():\n",
        "    \"\"\"Get current memory usage in bytes\"\"\"\n",
        "    process = psutil.Process(os.getpid())\n",
        "    return process.memory_info().rss\n",
        "\n",
        "def get_system_info():\n",
        "    \"\"\"Get system information similar to Java version\"\"\"\n",
        "    system_info = {\n",
        "        \"available_processors\": multiprocessing.cpu_count(),\n",
        "        \"max_memory_mb\": psutil.virtual_memory().total / (1024.0 * 1024.0),\n",
        "        \"total_memory_mb\": psutil.Process().memory_info().rss / (1024.0 * 1024.0),\n",
        "        \"os_name\": platform.system(),\n",
        "        \"os_version\": platform.version(),\n",
        "        \"os_arch\": platform.machine(),\n",
        "        \"python_version\": platform.python_version(),\n",
        "    }\n",
        "    return system_info\n",
        "\n",
        "def train_network(model):\n",
        "    \"\"\"Train the network with same parameters as Java version\"\"\"\n",
        "    # Force garbage collection before measurement\n",
        "    gc.collect()\n",
        "    time.sleep(0.1)\n",
        "    \n",
        "    start_mem = get_used_memory()\n",
        "    start_cpu_time = time.process_time()\n",
        "    \n",
        "    # Track memory during training with 100ms intervals, same as Java\n",
        "    with MemoryTracker(interval_ms=100) as memory_tracker:\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Load and preprocess MNIST dataset\n",
        "        print(\"Loading data...\")\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "        x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "        \n",
        "        # Match Java training parameters\n",
        "        batch_size = 256  # Same as Java\n",
        "        num_epochs = 10  # Same as Java\n",
        "        \n",
        "        print(\"Starting training...\")\n",
        "        # Training with callback to match the score iteration listener in Java\n",
        "        class ScoreLogger(tf.keras.callbacks.Callback):\n",
        "            def on_batch_end(self, batch, logs=None):\n",
        "                if batch % 100 == 0:\n",
        "                    print(f\"Batch {batch}, loss: {logs['loss']:.4f}\")\n",
        "        \n",
        "        for i in range(num_epochs):\n",
        "            print(f\"Epoch {i+1}/{num_epochs}\")\n",
        "            model.fit(\n",
        "                x_train, y_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=1,\n",
        "                verbose=0,\n",
        "                callbacks=[ScoreLogger()]\n",
        "            )\n",
        "        \n",
        "        print(\"Training complete!\")\n",
        "        \n",
        "        # Evaluate on test data\n",
        "        print(\"Evaluating model...\")\n",
        "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "        print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "        print(f\"Test loss: {test_loss:.4f}\")\n",
        "        \n",
        "        end_time = time.time()\n",
        "        \n",
        "    end_cpu_time = time.process_time()\n",
        "    end_mem = get_used_memory()\n",
        "    \n",
        "    time_ms = (end_time - start_time) * 1000\n",
        "    memory_used_mb = (end_mem - start_mem) / (1024.0 * 1024.0)\n",
        "    cpu_time_ms = (end_cpu_time - start_cpu_time) * 1000\n",
        "    peak_memory_mb = memory_tracker.get_peak_memory_mb()\n",
        "    \n",
        "    # Create memory profile JSON\n",
        "    memory_profile = {\n",
        "        \"summary\": memory_tracker.get_summary(),\n",
        "        \"timeseries\": memory_tracker.get_timeseries_data()\n",
        "    }\n",
        "    \n",
        "    result = TrainingResult(\n",
        "        time_ms=time_ms,\n",
        "        memory_used_mb=memory_used_mb,\n",
        "        cpu_time_ms=cpu_time_ms,\n",
        "        peak_memory_mb=peak_memory_mb,\n",
        "        accuracy=test_acc,\n",
        "        memory_profile=memory_profile\n",
        "    )\n",
        "    \n",
        "    return result, x_test, y_test\n",
        "\n",
        "def warmup_iteration(model, image_file):\n",
        "    \"\"\"Perform warmup iterations just like Java version\"\"\"\n",
        "    try:\n",
        "        # Load and preprocess the image\n",
        "        img = Image.open(image_file).convert('L')  # Convert to grayscale\n",
        "        img = img.resize((28, 28))  # Resize to MNIST dimensions\n",
        "        \n",
        "        # Convert to numpy array and normalize\n",
        "        img_array = np.array(img)\n",
        "        img_array = img_array / 255.0\n",
        "        \n",
        "        # Reshape for the model (add batch dimension)\n",
        "        img_array = img_array.reshape(1, 28, 28)\n",
        "        \n",
        "        # Run prediction\n",
        "        _ = model.predict(img_array, verbose=0)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Warmup iteration failed: {e}\")\n",
        "        # If image loading fails, create a random image for warmup\n",
        "        img_array = np.random.random((1, 28, 28))\n",
        "        _ = model.predict(img_array, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_network(model, image_file):\n",
        "    \"\"\"Test the network with detailed metrics matching Java version\"\"\"\n",
        "    # Force garbage collection before measurement\n",
        "    gc.collect()\n",
        "    time.sleep(0.1)\n",
        "    \n",
        "    start_mem = get_used_memory()\n",
        "    start_cpu_time = time.process_time()\n",
        "    \n",
        "    # Track memory during inference with 10ms intervals, same as Java\n",
        "    with MemoryTracker(interval_ms=10) as memory_tracker:\n",
        "        start_time = time.time()\n",
        "        \n",
        "        try:\n",
        "            # Load and preprocess the image\n",
        "            img = Image.open(image_file).convert('L')  # Convert to grayscale\n",
        "            img = img.resize((28, 28))  # Resize to MNIST dimensions\n",
        "            \n",
        "            # Convert to numpy array and normalize\n",
        "            img_array = np.array(img)\n",
        "            img_array = img_array / 255.0\n",
        "            \n",
        "            # Reshape for the model (add batch dimension)\n",
        "            img_array = img_array.reshape(1, 28, 28)\n",
        "            \n",
        "            # Run prediction\n",
        "            predictions = model.predict(img_array, verbose=0)\n",
        "            prediction = np.argmax(predictions[0])\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Image processing failed: {e}\")\n",
        "            # If image loading fails, use random data\n",
        "            img_array = np.random.random((1, 28, 28))\n",
        "            predictions = model.predict(img_array, verbose=0)\n",
        "            prediction = np.argmax(predictions[0])\n",
        "        \n",
        "        end_time = time.time()\n",
        "    \n",
        "    end_cpu_time = time.process_time()\n",
        "    end_mem = get_used_memory()\n",
        "    \n",
        "    time_ms = (end_time - start_time) * 1000\n",
        "    memory_used_mb = (end_mem - start_mem) / (1024.0 * 1024.0)\n",
        "    cpu_time_ms = (end_cpu_time - start_cpu_time) * 1000\n",
        "    peak_memory_mb = memory_tracker.get_peak_memory_mb()\n",
        "    \n",
        "    # Create memory profile JSON\n",
        "    memory_profile = {\n",
        "        \"summary\": memory_tracker.get_summary(),\n",
        "        \"timeseries\": memory_tracker.get_timeseries_data()\n",
        "    }\n",
        "    \n",
        "    print(f\"Prediction: {prediction}\")\n",
        "    print(f\"Execution time (wall): {time_ms:.2f} ms\")\n",
        "    print(f\"CPU time: {cpu_time_ms:.2f} ms\")\n",
        "    print(f\"Memory used (end-start): {memory_used_mb:.2f} MB\")\n",
        "    print(f\"Peak memory used: {peak_memory_mb:.2f} MB\")\n",
        "    \n",
        "    result = InferenceResult(\n",
        "        prediction=prediction,\n",
        "        time_ms=time_ms,\n",
        "        memory_used_mb=memory_used_mb,\n",
        "        cpu_time_ms=cpu_time_ms,\n",
        "        peak_memory_mb=peak_memory_mb,\n",
        "        memory_profile=memory_profile\n",
        "    )\n",
        "    \n",
        "    return result\n",
        "\n",
        "def average(values):\n",
        "    \"\"\"Calculate average of values\"\"\"\n",
        "    return sum(values) / len(values) if values else 0\n",
        "\n",
        "def std_dev(values):\n",
        "    \"\"\"Calculate standard deviation\"\"\"\n",
        "    if not values or len(values) < 2:\n",
        "        return 0\n",
        "    return statistics.stdev(values)\n",
        "\n",
        "def mode(values):\n",
        "    \"\"\"Find the most common value\"\"\"\n",
        "    return max(set(values), key=values.count)\n",
        "\n",
        "def save_to_json(\n",
        "        training_result,\n",
        "        inference_results,\n",
        "        create_time_ms,\n",
        "        avg_inference_time,\n",
        "        std_dev_inference_time,\n",
        "        avg_memory,\n",
        "        std_dev_memory,\n",
        "        avg_peak_memory,\n",
        "        std_dev_peak_memory,\n",
        "        common_prediction):\n",
        "    \"\"\"Save results to JSON file, matching Java version\"\"\"\n",
        "    \n",
        "    root = {\n",
        "        \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + datetime.datetime.now().strftime(\"%z\"),\n",
        "        \"system_info\": get_system_info(),\n",
        "        \"model_creation\": {\n",
        "            \"time_ms\": create_time_ms\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Add training info - exclude timeseries from memory_profile\n",
        "    training_obj = {\n",
        "        \"time_ms\": training_result.time_ms,\n",
        "        \"cpu_time_ms\": training_result.cpu_time_ms,\n",
        "        \"memory_used_mb\": training_result.memory_used_mb,\n",
        "        \"peak_memory_mb\": training_result.peak_memory_mb,\n",
        "        \"accuracy\": training_result.accuracy,\n",
        "        \"memory_profile\": {\n",
        "            \"summary\": training_result.memory_profile[\"summary\"]\n",
        "        }\n",
        "    }\n",
        "    root[\"training\"] = training_obj\n",
        "    \n",
        "    # Add inference runs - exclude timeseries from memory_profile\n",
        "    inference_runs = []\n",
        "    for i, result in enumerate(inference_results):\n",
        "        run_obj = {\n",
        "            \"run\": i + 1,\n",
        "            \"prediction\": int(result.prediction),  # Convert numpy.int64 to regular int\n",
        "            \"execution_time_ms\": result.time_ms,\n",
        "            \"cpu_time_ms\": result.cpu_time_ms,\n",
        "            \"memory_used_mb\": result.memory_used_mb,\n",
        "            \"peak_memory_mb\": result.peak_memory_mb,\n",
        "            \"memory_profile\": {\n",
        "                \"summary\": result.memory_profile[\"summary\"]\n",
        "            }\n",
        "        }\n",
        "        inference_runs.append(run_obj)\n",
        "    root[\"inference_runs\"] = inference_runs\n",
        "    \n",
        "    # Add summary with all metrics\n",
        "    root[\"summary\"] = {\n",
        "        \"model_creation_time_ms\": create_time_ms,\n",
        "        \"training_time_ms\": training_result.time_ms,\n",
        "        \"training_peak_memory_mb\": training_result.peak_memory_mb,\n",
        "        \"average_inference_time_ms\": avg_inference_time,\n",
        "        \"std_dev_inference_time_ms\": std_dev_inference_time,\n",
        "        \"average_inference_memory_mb\": avg_memory,\n",
        "        \"std_dev_inference_memory_mb\": std_dev_memory,\n",
        "        \"average_inference_peak_memory_mb\": avg_peak_memory,\n",
        "        \"std_dev_inference_peak_memory_mb\": std_dev_peak_memory,\n",
        "        \"most_common_prediction\": int(common_prediction),  # Convert numpy.int64 to regular int\n",
        "        \"total_time_ms\": create_time_ms + training_result.time_ms + avg_inference_time\n",
        "    }\n",
        "    \n",
        "    with open(\"easy_memory_results_python256.json\", \"w\") as f:\n",
        "        json.dump(root, f, indent=4)\n",
        "    print(\"Results exported to easy_memory_results_python.json\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCb2HcY_j2mC",
        "outputId": "4a1150cc-30c0-4604-aef2-c627281d8259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Creating network model ====\n",
            "Model creation time: 24.43 ms\n",
            "\n",
            "==== Training network model ====\n",
            "Loading data...\n",
            "Starting training...\n",
            "Epoch 1/10\n",
            "Batch 0, loss: 2.4024\n",
            "Batch 100, loss: 0.8233\n",
            "Batch 200, loss: 0.5836\n",
            "Epoch 2/10\n",
            "Batch 0, loss: 0.2616\n",
            "Batch 100, loss: 0.2623\n",
            "Batch 200, loss: 0.2505\n",
            "Epoch 3/10\n",
            "Batch 0, loss: 0.2053\n",
            "Batch 100, loss: 0.2046\n",
            "Batch 200, loss: 0.1983\n",
            "Epoch 4/10\n",
            "Batch 0, loss: 0.1631\n",
            "Batch 100, loss: 0.1704\n",
            "Batch 200, loss: 0.1629\n",
            "Epoch 5/10\n",
            "Batch 0, loss: 0.1517\n",
            "Batch 100, loss: 0.1459\n",
            "Batch 200, loss: 0.1389\n",
            "Epoch 6/10\n",
            "Batch 0, loss: 0.1207\n",
            "Batch 100, loss: 0.1207\n",
            "Batch 200, loss: 0.1217\n",
            "Epoch 7/10\n",
            "Batch 0, loss: 0.1497\n",
            "Batch 100, loss: 0.1076\n",
            "Batch 200, loss: 0.1086\n",
            "Epoch 8/10\n",
            "Batch 0, loss: 0.1378\n",
            "Batch 100, loss: 0.0966\n",
            "Batch 200, loss: 0.0986\n",
            "Epoch 9/10\n",
            "Batch 0, loss: 0.1280\n",
            "Batch 100, loss: 0.0859\n",
            "Batch 200, loss: 0.0891\n",
            "Epoch 10/10\n",
            "Batch 0, loss: 0.0910\n",
            "Batch 100, loss: 0.0783\n",
            "Batch 200, loss: 0.0792\n",
            "Training complete!\n",
            "Evaluating model...\n",
            "Test accuracy: 0.9695\n",
            "Test loss: 0.0987\n",
            "Training time: 6988.80 ms\n",
            "Training memory used: 1178.05 MB\n",
            "Training peak memory: 1732.19 MB\n",
            "\n",
            "==== Performing warm-up iterations ====\n",
            "Warm-up complete, starting inference benchmark...\n",
            "\n",
            "==== Running inference benchmark ====\n",
            "\n",
            "--- Inference Test Run 1 ---\n",
            "Prediction: 2\n",
            "Execution time (wall): 46.88 ms\n",
            "CPU time: 218.75 ms\n",
            "Memory used (end-start): 0.21 MB\n",
            "Peak memory used: 431.51 MB\n",
            "\n",
            "--- Inference Test Run 2 ---\n",
            "Prediction: 2\n",
            "Execution time (wall): 46.88 ms\n",
            "CPU time: 218.75 ms\n",
            "Memory used (end-start): 0.26 MB\n",
            "Peak memory used: 431.56 MB\n",
            "\n",
            "--- Inference Test Run 3 ---\n",
            "Prediction: 2\n",
            "Execution time (wall): 34.47 ms\n",
            "CPU time: 203.12 ms\n",
            "Memory used (end-start): 0.36 MB\n",
            "Peak memory used: 431.76 MB\n",
            "\n",
            "--- Inference Test Run 4 ---\n",
            "Prediction: 2\n",
            "Execution time (wall): 41.90 ms\n",
            "CPU time: 218.75 ms\n",
            "Memory used (end-start): 0.02 MB\n",
            "Peak memory used: 432.04 MB\n",
            "\n",
            "--- Inference Test Run 5 ---\n",
            "Prediction: 2\n",
            "Execution time (wall): 49.63 ms\n",
            "CPU time: 203.12 ms\n",
            "Memory used (end-start): 0.04 MB\n",
            "Peak memory used: 432.05 MB\n",
            "\n",
            "===== Average Results After 5 Inference Runs =====\n",
            "Most common prediction: 2\n",
            "Average inference time: 43.95 ms (±5.99)\n",
            "Average inference memory used: 0.18 MB (±0.15)\n",
            "Average inference peak memory: 431.78 MB (±0.26)\n",
            "\n",
            "===== Combined Results =====\n",
            "Model creation time: 24.43 ms\n",
            "Training time: 6988.80 ms\n",
            "Training memory used: 1178.05 MB\n",
            "Training peak memory: 1732.19 MB\n",
            "Average inference time: 43.95 ms (±5.99)\n",
            "Total time (creation + training + avg inference): 7057.18 ms\n",
            "Results exported to easy_memory_results_python.json\n",
            "Model saved to trained-easy-model.h5\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # First, measure model creation time\n",
        "    print(\"==== Creating network model ====\")\n",
        "    start_create_time = time.time()\n",
        "    model = create_easy_network()\n",
        "    end_create_time = time.time()\n",
        "    create_time_ms = (end_create_time - start_create_time) * 1000\n",
        "    print(f\"Model creation time: {create_time_ms:.2f} ms\")\n",
        "    \n",
        "    # Next, measure training time\n",
        "    print(\"\\n==== Training network model ====\")\n",
        "    training_result, x_test, y_test = train_network(model)\n",
        "    print(f\"Training time: {training_result.time_ms:.2f} ms\")\n",
        "    print(f\"Training memory used: {training_result.memory_used_mb:.2f} MB\")\n",
        "    print(f\"Training peak memory: {training_result.peak_memory_mb:.2f} MB\")\n",
        "    \n",
        "    # Determine test image path\n",
        "    image_file = \"./träningsbilder/testSample/img_1.jpg\"\n",
        "    if not os.path.exists(image_file):\n",
        "        print(f\"Warning: Test image not found at {image_file}\")\n",
        "        print(f\"Will try to use a random test sample from MNIST instead for inference\")\n",
        "        # Select random test image from MNIST\n",
        "        test_idx = np.random.randint(0, len(x_test))\n",
        "        # Save the test image for visualization\n",
        "        test_img = x_test[test_idx]\n",
        "        os.makedirs(\"./träningsbilder/testSample\", exist_ok=True)\n",
        "        Image.fromarray((test_img * 255).astype(np.uint8)).save(image_file)\n",
        "        print(f\"Created test image at {image_file}\")\n",
        "\n",
        "    # Add explicit warm-up phase\n",
        "    print(\"\\n==== Performing warm-up iterations ====\")\n",
        "    for i in range(10):\n",
        "        warmup_iteration(model, image_file)\n",
        "    print(\"Warm-up complete, starting inference benchmark...\")\n",
        "    \n",
        "    # Force garbage collection and wait\n",
        "    gc.collect()\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    runs = 5\n",
        "    inference_results = []\n",
        "    \n",
        "    print(\"\\n==== Running inference benchmark ====\")\n",
        "    for i in range(runs):\n",
        "        print(f\"\\n--- Inference Test Run {i + 1} ---\")\n",
        "        inference_result = test_network(model, image_file)\n",
        "        inference_results.append(inference_result)\n",
        "    \n",
        "    # Aggregate inference metrics\n",
        "    avg_inference_time = average([r.time_ms for r in inference_results])\n",
        "    std_dev_inference_time = std_dev([r.time_ms for r in inference_results])\n",
        "    \n",
        "    avg_inference_memory = average([r.memory_used_mb for r in inference_results])\n",
        "    std_dev_inference_memory = std_dev([r.memory_used_mb for r in inference_results])\n",
        "    \n",
        "    avg_inference_peak_memory = average([r.peak_memory_mb for r in inference_results])\n",
        "    std_dev_inference_peak_memory = std_dev([r.peak_memory_mb for r in inference_results])\n",
        "    \n",
        "    common_prediction = mode([r.prediction for r in inference_results])\n",
        "    \n",
        "    print(\"\\n===== Average Results After 5 Inference Runs =====\")\n",
        "    print(f\"Most common prediction: {common_prediction}\")\n",
        "    print(f\"Average inference time: {avg_inference_time:.2f} ms (±{std_dev_inference_time:.2f})\")\n",
        "    print(f\"Average inference memory used: {avg_inference_memory:.2f} MB (±{std_dev_inference_memory:.2f})\")\n",
        "    print(f\"Average inference peak memory: {avg_inference_peak_memory:.2f} MB (±{std_dev_inference_peak_memory:.2f})\")\n",
        "    \n",
        "    print(\"\\n===== Combined Results =====\")\n",
        "    print(f\"Model creation time: {create_time_ms:.2f} ms\")\n",
        "    print(f\"Training time: {training_result.time_ms:.2f} ms\")\n",
        "    print(f\"Training memory used: {training_result.memory_used_mb:.2f} MB\")\n",
        "    print(f\"Training peak memory: {training_result.peak_memory_mb:.2f} MB\")\n",
        "    print(f\"Average inference time: {avg_inference_time:.2f} ms (±{std_dev_inference_time:.2f})\")\n",
        "    print(f\"Total time (creation + training + avg inference): {create_time_ms + training_result.time_ms + avg_inference_time:.2f} ms\")\n",
        "    \n",
        "    # Save comprehensive results to JSON\n",
        "    save_to_json(\n",
        "        training_result,\n",
        "        inference_results,\n",
        "        create_time_ms,\n",
        "        avg_inference_time,\n",
        "        std_dev_inference_time,\n",
        "        avg_inference_memory,\n",
        "        std_dev_inference_memory,\n",
        "        avg_inference_peak_memory,\n",
        "        std_dev_inference_peak_memory,\n",
        "        common_prediction\n",
        "    )\n",
        "    \n",
        "    # Save the model\n",
        "    model.save(\"trained-easy-model.h5\")\n",
        "    print(\"Model saved to trained-easy-model.h5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOsO2AbqqWazRZsvwOKR9kL",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "exJobbEnv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
